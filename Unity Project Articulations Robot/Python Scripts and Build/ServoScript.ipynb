{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a1970a-70fc-4997-934e-e02558918bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -q pyserial\n",
    "\n",
    "from MathTools import get_rotate_offset_position\n",
    "from MathTools import RotateAxis\n",
    "from MathTools import normalize_coordinates\n",
    "\n",
    "from DDPGAgent import DDPGAgent\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "import serial, struct, time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af473b24-c39a-4eda-b10d-bb332c140e85",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7206709d-3323-4a62-a7c1-822e7fa4a6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Servo_lx16a:\n",
    "    \n",
    "    def __init__(self, ID, Port, Interlock = False):\n",
    "        self.ID = ID # unique servo ID\n",
    "        self.Port = Port # COM port features for later use \n",
    "        self.Interlock = Interlock # While Interlock = True, Servo will not move\n",
    "        \n",
    "    @staticmethod   \n",
    "    def checksum(msg):\n",
    "        #Checksum=~(ID+Length+Cmd+Prm1+...+PrmN)\n",
    "        #If the numbers in the brackets exceeds 255,\n",
    "        #Take the lowest one byte, \"~\" means Negation.\n",
    "        s = sum(msg)\n",
    "        s = ~s&255\n",
    "        chksum = s.to_bytes(1, byteorder ='little')\n",
    "        return chksum\n",
    "    \n",
    "    @staticmethod  \n",
    "    def display_msg(msg):\n",
    "        #dispalys bytes in python console not as ASCII symbols but as bytes\n",
    "        #print(''.join(r'\\x'+hex(letter)[2:] for letter in msg))\n",
    "        pass\n",
    "      \n",
    "    @staticmethod     \n",
    "    def time(current_position, target_position):\n",
    "        #currently not used\n",
    "        #range of time for Servo movement is 0~30000ms\n",
    "        #3000ms for 1000 steps\n",
    "        #y ms for N steps\n",
    "        #y = N*3000/1000\n",
    "        return abs(target_position-current_position)*3000/1000\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_angle(position):\n",
    "        #returns Servo angle from Servo position\n",
    "        #Range of position is 0..1000 which is equal to 0..240 deg\n",
    "        #240 degree equals to 1000 \n",
    "        #x degree equals to N\n",
    "        #x= (N*240/1000)\n",
    "        return position*240/1000\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_position(angle):\n",
    "        #return position from angle\n",
    "        return int(angle*1000/240)\n",
    "    \n",
    "    Header = b'\\x55\\x55' #every message transfered and recieved starts with this Header\n",
    "    \n",
    "    def ReadPosition(self):\n",
    "        #Reads current position of Servo \n",
    "        temp = self.ID+b'\\x03'+b'\\x1c' \n",
    "        msg = self.Header + temp + self.checksum(temp) #message to read Servo position\n",
    "        #print(f'Reading position of servo {int.from_bytes(self.ID, \"little\")}, sent:')\n",
    "        self.display_msg(msg)\n",
    "\n",
    "        wait = True\n",
    "        data_in = b'' # receive answer in data_in while wait True\n",
    "        ser.write(msg) #send message to COM\n",
    "        while wait:\n",
    "            while ser.in_waiting:\n",
    "                data_in += ser.readline()\n",
    "                #print('Received: ')\n",
    "                self.display_msg(data_in)\n",
    "                if len(data_in)>=8: wait = False\n",
    "        received_chksum = self.checksum(data_in[-6:-1]) \n",
    "        if data_in.startswith(self.Header): #check that received data_in startswith Header and that checksum is correct\n",
    "            #print('Message Header correct')\n",
    "            if  (received_chksum == data_in[-1].to_bytes(1, 'big')):\n",
    "                #print('Checksum correct')\n",
    "                position = struct.unpack('<h', data_in[-3:-1])[0]\n",
    "                angle = self.to_angle(position)\n",
    "                #print(f'Current position {position}, {angle}')\n",
    "                #print('---------------------------------------')\n",
    "                return angle\n",
    "            else:\n",
    "                print('Bad checksum')\n",
    "        else:\n",
    "            print('Bad message header')\n",
    "\n",
    "\n",
    "\n",
    "    def MoveServo(self, target_angle):\n",
    "        #Moves servo to traget angle\n",
    "        if self.Interlock:\n",
    "            print('Servo is Interlocked') #if Servo is interlocked, it will not move\n",
    "        else:\n",
    "            target_position = self.to_position(target_angle) \n",
    "            temp = self.ID+b'\\x07'+b'\\x01'+struct.pack('<h', target_position)+struct.pack('<h', 1500) #set time temporary to 1500 ms for any movement\n",
    "            msg = self.Header+temp+self.checksum(temp) # message to move servo to desired position\n",
    "            #print(f'Move servo {int.from_bytes(self.ID, \"little\")} to {target_position}, sent:')\n",
    "            self.display_msg(msg)\n",
    "            self.Interlock = True #Interlock servo\n",
    "            ser.write(msg) #sending message to COM\n",
    "            #This while cycle switches Interlock to False, when Servo reaches target position\n",
    "            while self.Interlock:\n",
    "                current_angle = self.ReadPosition()\n",
    "                angle_diff = abs(current_angle-target_angle)\n",
    "                #print('Angle_difference:', angle_diff)\n",
    "                #print('---------------------------------------')\n",
    "                if angle_diff<0.8:\n",
    "                    self.Interlock=False\n",
    "                    #print('Reached target angle +- 1 deg')\n",
    "                    #print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cd80fec-4571-47e2-b763-4928456b92ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0151087040722454, 0.8343491981978997, 0.07299609626426051]\n"
     ]
    }
   ],
   "source": [
    "test_result = get_rotate_offset_position(RotateAxis.OY, 0, RotateAxis.OX, 5, RotateAxis.OZ, 2,\n",
    "                                             RotateAxis.OY, 0.4048796, [0, 0.8378, 0])\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099530fa-5b1e-44ee-b1ba-36433f457787",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Servo settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4bca50-c553-4f24-af51-6167cc218e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db9c7207-fba6-4198-a4d9-339f04649186",
   "metadata": {},
   "outputs": [],
   "source": [
    "Servo1_ID = b'\\x01'\n",
    "Servo2_ID = b'\\x02'\n",
    "Servo3_ID = b'\\x03'\n",
    "\n",
    "com = 'COM9' #COM port id|\n",
    "baudrate = 115200 #COM speed\n",
    "\n",
    "ser = serial.Serial(com, baudrate, timeout=0.2)\n",
    "Servo1 = Servo_lx16a(Servo1_ID, ser)\n",
    "Servo2 = Servo_lx16a(Servo2_ID, ser) # 0 - 110\n",
    "Servo3 = Servo_lx16a(Servo3_ID, ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b1963d-74f2-409a-8da5-66cd3f33f6aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da57424c-70bd-4b97-9d41-38b3583ce6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = 12\n",
    "action_size = 3\n",
    "agent = DDPGAgent(state_size = state_size - 3, action_size = action_size, goal_size = 3, \n",
    "                  action_high = 5, action_low = -5, \n",
    "                  actor_learning_rate = 1e-3, critic_learning_rate = 1e-3,\n",
    "                  tau = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "483f721d-155a-45fd-a6fb-f80773e4ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Servo():\n",
    "    def __init__(self):\n",
    "        self.angle = 0\n",
    "\n",
    "    def rotate(self, delta_angle):\n",
    "        self.angle += delta_angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6503500-fbe0-49d4-b44a-f24ccf352bae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_state_test(servo1, servo2, servo3):\n",
    "    # текущие углы роборуки\n",
    "    firstAngle = servo1.angle;\n",
    "    secondAngle = servo2.angle;\n",
    "    thirdAngle = servo3.angle;\n",
    "        \n",
    "    # длины двух сочленений роборуки\n",
    "    firstHandLength = 12 #0.4048796\n",
    "    secondHandLength = 9 #0.4048796\n",
    "    \n",
    "    # общая длина руки в вытянутом состоянии\n",
    "    allHandLength = firstHandLength + secondHandLength\n",
    "    \n",
    "    # позиция конца роборуки в вытянутом состоянии\n",
    "    defaultEndPosition = [0, allHandLength, 0]\n",
    "    \n",
    "    # не надо нормализовать, тк мы находим позицию для настоящих углов и длин, после чего нормализуем найденную позицию\n",
    "    #defaultEndPosition = normalize_coordinates(allHandLength, 1, defaultEndPosition)\n",
    "    \n",
    "    # поиск позиции конца роборуки по её углам и осям вращения\n",
    "    endPosition = get_rotate_offset_position(RotateAxis.OY, firstAngle, \n",
    "                                             RotateAxis.OX, secondAngle, \n",
    "                                             RotateAxis.OX, thirdAngle,\n",
    "                                             RotateAxis.OY, firstHandLength, \n",
    "                                             defaultEndPosition)\n",
    "    \n",
    "    # не надо нормализовать, из-за этого находится неправильная позиция\n",
    "    #endPosition = normalize_coordinates(allHandLength, 1, endPosition)\n",
    "    \n",
    "    cubePosition = [0, 12, 0]\n",
    "    #cubePosition = normalize_coordinates(allHandLength, 1, cubePosition)\n",
    "    \n",
    "    print(f'defaultEndPosition = {defaultEndPosition}; rotated endPosition = {endPosition}; cubePosition = {cubePosition}')\n",
    "    \n",
    "    # векторное расстояние между концом руки и целью\n",
    "    vectorDistance = [cubePosition[0] - endPosition[0], \n",
    "                      cubePosition[1] - endPosition[1], \n",
    "                      cubePosition[2] - endPosition[2]]\n",
    "    \n",
    "    firstAngle = firstAngle/360\n",
    "    secondAngle = secondAngle/360\n",
    "    thirdAngle = thirdAngle/360\n",
    "    \n",
    "    state = [vectorDistance[0], vectorDistance[1], vectorDistance[2], \n",
    "              endPosition[0], endPosition[1], endPosition[2],\n",
    "              firstAngle, secondAngle, thirdAngle]\n",
    "    \n",
    "    goal = [cubePosition[0], cubePosition[1], cubePosition[2]]\n",
    "    return state, goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ebf61a1-fbed-40c5-b4a7-c525ac0d2940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_state():\n",
    "    # так как рука в вытянутом состоянии имеет значения углов (120, 120, 120) (для возможности вращаться в обе стороны, тк имеет ограничение [0, 240])\n",
    "    firstAngle = Servo1.ReadPosition() - 120 #Servo1.ReadPosition() + 120;\n",
    "    secondAngle = Servo2.ReadPosition() - 120 #Servo2.ReadPosition() + 120;\n",
    "    thirdAngle = Servo3.ReadPosition() - 120 #240 - Servo3.ReadPosition() + 120;\n",
    "    \n",
    "    print(\"\\n firstAngle = \", firstAngle, \" secondAngle = \", secondAngle, \" thirdAngle = \", thirdAngle, \"\\n\")\n",
    "    \n",
    "    # длины двух сочленений роборуки\n",
    "    firstHandLength = 12\n",
    "    secondHandLength = 9\n",
    "    \n",
    "    # общая длина руки в вытянутом состоянии\n",
    "    allHandLength = firstHandLength + secondHandLength\n",
    "    \n",
    "    # позиция конца роборуки в вытянутом состоянии\n",
    "    defaultEndPosition = [0, allHandLength, 0]\n",
    "    \n",
    "    # надо ли нормализовать?????\n",
    "    #defaultEndPosition = normalize_coordinates(allHandLength, 1, defaultEndPosition)\n",
    "    \n",
    "    # поиск позиции конца роборуки по её углам и осям вращения\n",
    "    endPosition = get_rotate_offset_position(RotateAxis.OY, firstAngle, \n",
    "                                             RotateAxis.OX, secondAngle, \n",
    "                                             RotateAxis.OX, thirdAngle,\n",
    "                                             RotateAxis.OY, firstHandLength, \n",
    "                                             defaultEndPosition)\n",
    "    \n",
    "    print(f'not normalize end pos: {endPosition}')\n",
    "    \n",
    "    #not normalize end pos: [-0.0007017679341761611, 1.0011229079971835, 0.08376541700570701]\n",
    "    #normalize end pos: [-3.341752067505529e-05, 0.04767251942843731, 0.0039888293812241436]\n",
    "    \n",
    "    #endPosition = normalize_coordinates(allHandLength, 1, endPosition)\n",
    "    \n",
    "    cubePosition = [-0.007918067592270591, 0.7898086317810685, 0.6300666310496583] #endPosition #[-10, 6, 0]\n",
    "    \n",
    "    #cubePosition = normalize_coordinates(allHandLength, 1, cubePosition)\n",
    "    \n",
    "    # векторное расстояние между концом руки и целью\n",
    "    vectorDistance = [cubePosition[0] - endPosition[0], \n",
    "                      cubePosition[1] - endPosition[1], \n",
    "                      cubePosition[2] - endPosition[2]]\n",
    "    \n",
    "    firstAngle = firstAngle/360\n",
    "    secondAngle = secondAngle/360\n",
    "    thirdAngle = thirdAngle/360\n",
    "    \n",
    "    state = [vectorDistance[0], vectorDistance[1], vectorDistance[2], \n",
    "              endPosition[0], endPosition[1], endPosition[2],\n",
    "              firstAngle, secondAngle, thirdAngle]\n",
    "    \n",
    "    goal = [cubePosition[0], cubePosition[1], cubePosition[2]]\n",
    "    return state, goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a28e612e-6290-4820-8a1e-43375cfb0c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " firstAngle =  -40.31999999999999  secondAngle =  -0.23999999999999488  thirdAngle =  -80.4 \n",
      "\n",
      "not normalize end pos: [-6.99032676138843, 10.210885907229931, 8.236879969108381]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Servo2.MoveServo(150) #end pos: [-0.007918067592270591, 0.7898086317810685, 0.6300666310496583] - повернулся в положительную сторону по z\n",
    "#Servo2.MoveServo(80) #end pos: [0.002591194524373274, 0.7871754797239352, -0.6185985076056891] - повернулся в отрицательную сторону по z\n",
    "\n",
    "#Servo3.MoveServo(150) #end pos: [0.04649725024516806, 2.4736152827448286, -5.550070567099335]\n",
    "#Servo3.MoveServo(80) #end pos: [-0.05975396614459472, 3.583286569751135, 7.132437445610642]\n",
    "\n",
    "#Servo3.MoveServo(40) #end pos: [-0.09056626981047014, 10.256364693800629, 10.81029922837861]\n",
    "#Servo1.MoveServo(150) # против часовой, end pos: [5.444508565215012, 10.256364693800629, 9.339598392843824]\n",
    "#Servo1.MoveServo(80) # по часовой, end pos: [-6.99032676138843, 10.210885907229931, 8.236879969108381]\n",
    "\n",
    "state, goal = read_state()\n",
    "\n",
    "done, distance = check_if_done(state[3:6], goal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8151e558-6a04-4f44-ac0b-93d43129d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_action(action):\n",
    "    angle1 = Servo1.ReadPosition() + action[0]\n",
    "    angle2 = Servo2.ReadPosition() + action[1]\n",
    "    \n",
    "    # так как 3 серва крутится в другую сторону, относительно 1 и 2 серв, то поворачиваем на -action[2]\n",
    "    angle3 = Servo3.ReadPosition() - action[2]\n",
    "    \n",
    "    if (angle1 >=0 and angle1 <= 240):\n",
    "        Servo1.MoveServo(angle1)\n",
    "    if angle2 >=0 and angle1 <= 240:\n",
    "        Servo2.MoveServo(angle2)\n",
    "    if angle3 >=0 and angle1 <= 240:    \n",
    "        Servo3.MoveServo(angle3)\n",
    "    \n",
    "def set_action_test(action, servo1, servo2, servo3):\n",
    "    servo1.rotate(action[0])\n",
    "    servo2.rotate(action[1])    \n",
    "    servo3.rotate(action[2])\n",
    "    \n",
    "    return servo1, servo2, servo3\n",
    "\n",
    "def check_if_done(hand, goal):\n",
    "    hand = np.array(hand)\n",
    "    goal = np.array(goal)\n",
    "    dist = np.linalg.norm(hand - goal)\n",
    "    if dist <= 0.05:\n",
    "        return True, dist\n",
    "    return False, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e6b71a-4a05-4a21-89e8-1c2d91db110a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Servo1.MoveServo(120)\n",
    "Servo2.MoveServo(120)\n",
    "Servo3.MoveServo(120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd8edd0-3b1a-4bab-9ed0-aff48c1e81fa",
   "metadata": {},
   "source": [
    "## Test actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8813074b-3bb6-4171-9f5f-4faeb78e3abb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_episodes = 1\n",
    "\n",
    "servo1 = Servo()\n",
    "servo2 = Servo()\n",
    "servo3 = Servo()\n",
    "\n",
    "distances = []\n",
    "\n",
    "test_rewards = []\n",
    "agent.saver.restore(agent.sess, \"model/without_her_rotate_scaled.ckpt\")\n",
    "for i_episode in range(n_episodes):\n",
    "    \n",
    "    state, goal = read_state_test(servo1, servo2, servo3)\n",
    "    \n",
    "    r = 0\n",
    "    while True:\n",
    "        action = agent.choose_action([state], [goal], 0)\n",
    "        print(\"\\n\\nACTION = \", action, \"\\n\\n\")\n",
    "        print(\"\\n\\nSTATE = \", state, \"\\n\\n\")\n",
    "        \n",
    "        # применяем углы к сервам\n",
    "        servo1, servo2, servo3 = set_action_test(action, servo1, servo2, servo3)\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        # получаем обновленный state\n",
    "        next_state, next_goal = read_state_test(servo1, servo2, servo3)\n",
    "        \n",
    "        done, distance = check_if_done(next_state[3:6], goal)\n",
    "        \n",
    "        reward = -1\n",
    "        \n",
    "        if done:\n",
    "            reward += 10\n",
    "        \n",
    "        r += reward\n",
    "        \n",
    "        print(\"\\n old state = \", state, \"\\n action = \", action, \"\\n new state = \", next_state, \"\\n distance = \", distance,\n",
    "              \"\\n current reward = \", reward, \"\\n cumulative reward = \", r, \"\\n\")\n",
    "        \n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"episode:\", i_episode+1, \"rewards: %.2f\" % r, end=\"\\r\")\n",
    "            test_rewards += [r]\n",
    "            break\n",
    "         \n",
    "        distances.append(distance)\n",
    "        plt.plot(distances, label=\"ddpg+her\")\n",
    "        plt.legend()\n",
    "        plt.title(\"epoch success rate (over 20 episodes)\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b9b17-5cc5-47c3-8de0-acd2966ced0a",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a644e7e5-9232-45e1-adf2-04fb959be521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Servo1.MoveServo(120)\n",
    "Servo2.MoveServo(120)\n",
    "Servo3.MoveServo(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ebc68-9429-4759-a0c6-b52caca0048c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/without_her_rotate_scaled.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/without_her_rotate_scaled.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " firstAngle =  -0.480000000000004  secondAngle =  -0.23999999999999488  thirdAngle =  -0.23999999999999488 \n",
      "\n",
      "not normalize end pos: [-0.0003509073637783973, 1.0002807333103656, 0.04188550121170425]\n",
      "\n",
      "\n",
      "ACTION =  [-4.96324921  5.          4.75140619]\n",
      "\n",
      "\n",
      "STATE =  [-0.007567160228492194, -0.21047210152929707, 0.5881811298379541, -0.0003509073637783973, 1.0002807333103656, 0.04188550121170425, -0.0013333333333333443, -0.0006666666666666524, -0.0006666666666666524]\n",
      "\n",
      " firstAngle =  -5.760000000000005  secondAngle =  4.799999999999997  thirdAngle =  -4.560000000000002 \n",
      "\n",
      "not normalize end pos: [-0.0961522998965016, 0.9580108136515386, 0.9532203461144535]\n",
      "\n",
      " old state =  [-0.007567160228492194, -0.21047210152929707, 0.5881811298379541, -0.0003509073637783973, 1.0002807333103656, 0.04188550121170425, -0.0013333333333333443, -0.0006666666666666524, -0.0006666666666666524] \n",
      " action =  [-4.96324921  5.          4.75140619] \n",
      " new state =  [0.08823423230423101, -0.1682021818704701, -0.3231537150647952, -0.0961522998965016, 0.9580108136515386, 0.9532203461144535, -0.016000000000000014, 0.013333333333333326, -0.012666666666666673] \n",
      " distance =  0.3748407359085756 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -1 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [ 4.81275749 -0.34229296  4.99996662]\n",
      "\n",
      "\n",
      "STATE =  [0.08823423230423101, -0.1682021818704701, -0.3231537150647952, -0.0961522998965016, 0.9580108136515386, 0.9532203461144535, -0.016000000000000014, 0.013333333333333326, -0.012666666666666673]\n",
      "\n",
      " firstAngle =  -1.6800000000000068  secondAngle =  4.799999999999997  thirdAngle =  -10.560000000000002 \n",
      "\n",
      "not normalize end pos: [-0.06180424416245591, 1.01345312419975, 2.1072068208833215]\n",
      "\n",
      " old state =  [0.08823423230423101, -0.1682021818704701, -0.3231537150647952, -0.0961522998965016, 0.9580108136515386, 0.9532203461144535, -0.016000000000000014, 0.013333333333333326, -0.012666666666666673] \n",
      " action =  [ 4.81275749 -0.34229296  4.99996662] \n",
      " new state =  [0.053886176570185323, -0.22364449241868145, -1.4771401898336631, -0.06180424416245591, 1.01345312419975, 2.1072068208833215, -0.004666666666666685, 0.013333333333333326, -0.02933333333333334] \n",
      " distance =  1.494946059039052 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -2 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [-1.50463915 -5.          5.        ]\n",
      "\n",
      "\n",
      "STATE =  [0.053886176570185323, -0.22364449241868145, -1.4771401898336631, -0.06180424416245591, 1.01345312419975, 2.1072068208833215, -0.004666666666666685, 0.013333333333333326, -0.02933333333333334]\n",
      "\n",
      " firstAngle =  -3.1200000000000045  secondAngle =  -0.480000000000004  thirdAngle =  -15.599999999999994 \n",
      "\n",
      "not normalize end pos: [-0.1603561925286305, 1.429944035675883, 2.941874965353036]\n",
      "\n",
      " old state =  [0.053886176570185323, -0.22364449241868145, -1.4771401898336631, -0.06180424416245591, 1.01345312419975, 2.1072068208833215, -0.004666666666666685, 0.013333333333333326, -0.02933333333333334] \n",
      " action =  [-1.50463915 -5.          5.        ] \n",
      " new state =  [0.15243812493635991, -0.6401354038948145, -2.311808334303378, -0.1603561925286305, 1.429944035675883, 2.941874965353036, -0.00866666666666668, -0.0013333333333333443, -0.04333333333333332] \n",
      " distance =  2.4036365140778355 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -3 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [ 4.98942327 -5.          5.        ]\n",
      "\n",
      "\n",
      "STATE =  [0.15243812493635991, -0.6401354038948145, -2.311808334303378, -0.1603561925286305, 1.429944035675883, 2.941874965353036, -0.00866666666666668, -0.0013333333333333443, -0.04333333333333332]\n",
      "\n",
      " firstAngle =  1.9200000000000017  secondAngle =  -6.0  thirdAngle =  -20.159999999999997 \n",
      "\n",
      "not normalize end pos: [0.12045815700236587, 2.0610325619465075, 3.593312704230603]\n",
      "\n",
      " old state =  [0.15243812493635991, -0.6401354038948145, -2.311808334303378, -0.1603561925286305, 1.429944035675883, 2.941874965353036, -0.00866666666666668, -0.0013333333333333443, -0.04333333333333332] \n",
      " action =  [ 4.98942327 -5.          5.        ] \n",
      " new state =  [-0.12837622459463646, -1.2712239301654389, -2.9632460731809447, 0.12045815700236587, 2.0610325619465075, 3.593312704230603, 0.005333333333333338, -0.016666666666666666, -0.05599999999999999] \n",
      " distance =  3.226967310942075 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -4 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [-4.19615269 -5.          5.        ]\n",
      "\n",
      "\n",
      "STATE =  [-0.12837622459463646, -1.2712239301654389, -2.9632460731809447, 0.12045815700236587, 2.0610325619465075, 3.593312704230603, 0.005333333333333338, -0.016666666666666666, -0.05599999999999999]\n",
      "\n",
      " firstAngle =  -2.4000000000000057  secondAngle =  -11.519999999999996  thirdAngle =  -25.92 \n",
      "\n",
      "not normalize end pos: [-0.17967643313179626, 3.024366243484773, 4.286949823723726]\n",
      "\n",
      " old state =  [-0.12837622459463646, -1.2712239301654389, -2.9632460731809447, 0.12045815700236587, 2.0610325619465075, 3.593312704230603, 0.005333333333333338, -0.016666666666666666, -0.05599999999999999] \n",
      " action =  [-4.19615269 -5.          5.        ] \n",
      " new state =  [0.17175836553952567, -2.2345576117037043, -3.6568831926740675, -0.17967643313179626, 3.024366243484773, 4.286949823723726, -0.006666666666666683, -0.03199999999999999, -0.07200000000000001] \n",
      " distance =  4.289002604454543 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -5 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [ 5. -5.  5.]\n",
      "\n",
      "\n",
      "STATE =  [0.17175836553952567, -2.2345576117037043, -3.6568831926740675, -0.17967643313179626, 3.024366243484773, 4.286949823723726, -0.006666666666666683, -0.03199999999999999, -0.07200000000000001]\n",
      "\n",
      " firstAngle =  2.1599999999999966  secondAngle =  -17.040000000000006  thirdAngle =  -30.72 \n",
      "\n",
      "not normalize end pos: [0.1744007296997946, 4.078591255386993, 4.623931243211049]\n",
      "\n",
      " old state =  [0.17175836553952567, -2.2345576117037043, -3.6568831926740675, -0.17967643313179626, 3.024366243484773, 4.286949823723726, -0.006666666666666683, -0.03199999999999999, -0.07200000000000001] \n",
      " action =  [ 5. -5.  5.] \n",
      " new state =  [-0.18231879729206518, -3.288782623605924, -3.993864612161391, 0.1744007296997946, 4.078591255386993, 4.623931243211049, 0.005999999999999991, -0.04733333333333335, -0.08533333333333333] \n",
      " distance =  5.176899248532209 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -6 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [ 5. -5.  5.]\n",
      "\n",
      "\n",
      "STATE =  [-0.18231879729206518, -3.288782623605924, -3.993864612161391, 0.1744007296997946, 4.078591255386993, 4.623931243211049, 0.005999999999999991, -0.04733333333333335, -0.08533333333333333]\n",
      "\n",
      " firstAngle =  6.719999999999999  secondAngle =  -23.040000000000006  thirdAngle =  -36.239999999999995 \n",
      "\n",
      "not normalize end pos: [0.5569946972584634, 5.423508817865985, 4.727228694833632]\n",
      "\n",
      " old state =  [-0.18231879729206518, -3.288782623605924, -3.993864612161391, 0.1744007296997946, 4.078591255386993, 4.623931243211049, 0.005999999999999991, -0.04733333333333335, -0.08533333333333333] \n",
      " action =  [ 5. -5.  5.] \n",
      " new state =  [-0.5649127648507339, -4.6337001860849165, -4.097162063783974, 0.5569946972584634, 5.423508817865985, 4.727228694833632, 0.018666666666666665, -0.06400000000000002, -0.10066666666666665] \n",
      " distance =  6.211041846850272 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -7 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [ 5. -5.  5.]\n",
      "\n",
      "\n",
      "STATE =  [-0.5649127648507339, -4.6337001860849165, -4.097162063783974, 0.5569946972584634, 5.423508817865985, 4.727228694833632, 0.018666666666666665, -0.06400000000000002, -0.10066666666666665]\n",
      "\n",
      " firstAngle =  11.280000000000001  secondAngle =  -28.319999999999993  thirdAngle =  -41.040000000000006 \n",
      "\n",
      "not normalize end pos: [0.9000131667157665, 6.686296132500578, 4.512322662877144]\n",
      "\n",
      " old state =  [-0.5649127648507339, -4.6337001860849165, -4.097162063783974, 0.5569946972584634, 5.423508817865985, 4.727228694833632, 0.018666666666666665, -0.06400000000000002, -0.10066666666666665] \n",
      " action =  [ 5. -5.  5.] \n",
      " new state =  [-0.907931234308037, -5.89648750071951, -3.8822560318274855, 0.9000131667157665, 6.686296132500578, 4.512322662877144, 0.03133333333333334, -0.07866666666666665, -0.11400000000000002] \n",
      " distance =  7.117922159523411 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -8 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [5. 5. 5.]\n",
      "\n",
      "\n",
      "STATE =  [-0.907931234308037, -5.89648750071951, -3.8822560318274855, 0.9000131667157665, 6.686296132500578, 4.512322662877144, 0.03133333333333334, -0.07866666666666665, -0.11400000000000002]\n",
      "\n",
      " firstAngle =  15.599999999999994  secondAngle =  -24.239999999999995  thirdAngle =  -45.599999999999994 \n",
      "\n",
      "not normalize end pos: [1.451993811419418, 7.15093240891122, 5.200457456729589]\n",
      "\n",
      " old state =  [-0.907931234308037, -5.89648750071951, -3.8822560318274855, 0.9000131667157665, 6.686296132500578, 4.512322662877144, 0.03133333333333334, -0.07866666666666665, -0.11400000000000002] \n",
      " action =  [5. 5. 5.] \n",
      " new state =  [-1.4599118790116885, -6.361123777130151, -4.570390825679931, 1.451993811419418, 7.15093240891122, 5.200457456729589, 0.04333333333333332, -0.06733333333333331, -0.12666666666666665] \n",
      " distance =  7.967666578234137 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -9 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [4.9983983 5.        5.       ]\n",
      "\n",
      "\n",
      "STATE =  [-1.4599118790116885, -6.361123777130151, -4.570390825679931, 1.451993811419418, 7.15093240891122, 5.200457456729589, 0.04333333333333332, -0.06733333333333331, -0.12666666666666665]\n",
      "\n",
      " firstAngle =  20.639999999999986  secondAngle =  -20.159999999999997  thirdAngle =  -51.120000000000005 \n",
      "\n",
      "not normalize end pos: [2.2145030490875897, 7.734426583967185, 5.879124278500886]\n",
      "\n",
      " old state =  [-1.4599118790116885, -6.361123777130151, -4.570390825679931, 1.451993811419418, 7.15093240891122, 5.200457456729589, 0.04333333333333332, -0.06733333333333331, -0.12666666666666665] \n",
      " action =  [4.9983983 5.        5.       ] \n",
      " new state =  [-2.22242111667986, -6.944617952186117, -5.249057647451228, 2.2145030490875897, 7.734426583967185, 5.879124278500886, 0.0573333333333333, -0.05599999999999999, -0.14200000000000002] \n",
      " distance =  8.984402056228143 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -10 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [-4.99999332  4.92942524  5.        ]\n",
      "\n",
      "\n",
      "STATE =  [-2.22242111667986, -6.944617952186117, -5.249057647451228, 2.2145030490875897, 7.734426583967185, 5.879124278500886, 0.0573333333333333, -0.05599999999999999, -0.14200000000000002]\n",
      "\n",
      " firstAngle =  16.080000000000013  secondAngle =  -15.599999999999994  thirdAngle =  -56.4 \n",
      "\n",
      "not normalize end pos: [2.0038296849961714, 8.158763863447476, 6.951537226670727]\n",
      "\n",
      " old state =  [-2.22242111667986, -6.944617952186117, -5.249057647451228, 2.2145030490875897, 7.734426583967185, 5.879124278500886, 0.0573333333333333, -0.05599999999999999, -0.14200000000000002] \n",
      " action =  [-4.99999332  4.92942524  5.        ] \n",
      " new state =  [-2.011747752588442, -7.3689552316664075, -6.321470595621069, 2.0038296849961714, 8.158763863447476, 6.951537226670727, 0.0446666666666667, -0.04333333333333332, -0.15666666666666668] \n",
      " distance =  9.915120812055198 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -11 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [ 4.9202528  -4.88969135  5.        ]\n",
      "\n",
      "\n",
      "STATE =  [-2.011747752588442, -7.3689552316664075, -6.321470595621069, 2.0038296849961714, 8.158763863447476, 6.951537226670727, 0.0446666666666667, -0.04333333333333332, -0.15666666666666668]\n",
      "\n",
      " firstAngle =  20.639999999999986  secondAngle =  -21.120000000000005  thirdAngle =  -61.44 \n",
      "\n",
      "not normalize end pos: [2.3206588353921433, 9.769567080459218, 6.160949612100491]\n",
      "\n",
      " old state =  [-2.011747752588442, -7.3689552316664075, -6.321470595621069, 2.0038296849961714, 8.158763863447476, 6.951537226670727, 0.0446666666666667, -0.04333333333333332, -0.15666666666666668] \n",
      " action =  [ 4.9202528  -4.88969135  5.        ] \n",
      " new state =  [-2.328576902984414, -8.97975844867815, -5.530882981050833, 2.3206588353921433, 9.769567080459218, 6.160949612100491, 0.0573333333333333, -0.05866666666666668, -0.17066666666666666] \n",
      " distance =  10.800416600288937 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -12 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [-4.99999475  5.          5.        ]\n",
      "\n",
      "\n",
      "STATE =  [-2.328576902984414, -8.97975844867815, -5.530882981050833, 2.3206588353921433, 9.769567080459218, 6.160949612100491, 0.0573333333333333, -0.05866666666666668, -0.17066666666666666]\n",
      "\n",
      " firstAngle =  15.840000000000003  secondAngle =  -17.040000000000006  thirdAngle =  -66.96000000000001 \n",
      "\n",
      "not normalize end pos: [2.026195840133044, 10.323391811797482, 7.141390892012484]\n",
      "\n",
      " old state =  [-2.328576902984414, -8.97975844867815, -5.530882981050833, 2.3206588353921433, 9.769567080459218, 6.160949612100491, 0.0573333333333333, -0.05866666666666668, -0.17066666666666666] \n",
      " action =  [-4.99999475  5.          5.        ] \n",
      " new state =  [-2.0341139077253145, -9.533583180016413, -6.511324260962826, 2.026195840133044, 10.323391811797482, 7.141390892012484, 0.04400000000000001, -0.04733333333333335, -0.18600000000000003] \n",
      " distance =  11.722805605796614 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -13 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [4.99924612 5.         5.        ]\n",
      "\n",
      "\n",
      "STATE =  [-2.0341139077253145, -9.533583180016413, -6.511324260962826, 2.026195840133044, 10.323391811797482, 7.141390892012484, 0.04400000000000001, -0.04733333333333335, -0.18600000000000003]\n",
      "\n",
      " firstAngle =  20.639999999999986  secondAngle =  -12.480000000000004  thirdAngle =  -72.24000000000001 \n",
      "\n",
      "not normalize end pos: [2.946908005914379, 10.704204900090323, 7.8235333255549735]\n",
      "\n",
      " old state =  [-2.0341139077253145, -9.533583180016413, -6.511324260962826, 2.026195840133044, 10.323391811797482, 7.141390892012484, 0.04400000000000001, -0.04733333333333335, -0.18600000000000003] \n",
      " action =  [4.99924612 5.         5.        ] \n",
      " new state =  [-2.9548260735066494, -9.914396268309254, -7.193466694505315, 2.946908005914379, 10.704204900090323, 7.8235333255549735, 0.0573333333333333, -0.03466666666666668, -0.2006666666666667] \n",
      " distance =  12.600484656341454 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -14 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [-4.99999475  5.          5.        ]\n",
      "\n",
      "\n",
      "STATE =  [-2.9548260735066494, -9.914396268309254, -7.193466694505315, 2.946908005914379, 10.704204900090323, 7.8235333255549735, 0.0573333333333333, -0.03466666666666668, -0.2006666666666667]\n",
      "\n",
      " firstAngle =  15.599999999999994  secondAngle =  -8.159999999999997  thirdAngle =  -77.03999999999999 \n",
      "\n",
      "not normalize end pos: [2.4897044995934037, 10.958050485072317, 8.917119500190298]\n",
      "\n",
      " old state =  [-2.9548260735066494, -9.914396268309254, -7.193466694505315, 2.946908005914379, 10.704204900090323, 7.8235333255549735, 0.0573333333333333, -0.03466666666666668, -0.2006666666666667] \n",
      " action =  [-4.99999475  5.          5.        ] \n",
      " new state =  [-2.497622567185674, -10.168241853291248, -8.28705286914064, 2.4897044995934037, 10.958050485072317, 8.917119500190298, 0.04333333333333332, -0.022666666666666658, -0.21399999999999997] \n",
      " distance =  13.35314592637522 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -15 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [4.9997282 5.        5.       ]\n",
      "\n",
      "\n",
      "STATE =  [-2.497622567185674, -10.168241853291248, -8.28705286914064, 2.4897044995934037, 10.958050485072317, 8.917119500190298, 0.04333333333333332, -0.022666666666666658, -0.21399999999999997]\n",
      "\n",
      " firstAngle =  20.159999999999997  secondAngle =  -3.3599999999999994  thirdAngle =  -82.32 \n",
      "\n",
      "not normalize end pos: [3.5379093286236456, 11.150776998971203, 9.636510860276006]\n",
      "\n",
      " old state =  [-2.497622567185674, -10.168241853291248, -8.28705286914064, 2.4897044995934037, 10.958050485072317, 8.917119500190298, 0.04333333333333332, -0.022666666666666658, -0.21399999999999997] \n",
      " action =  [4.9997282 5.        5.       ] \n",
      " new state =  [-3.545827396215916, -10.360968367190134, -9.006444229226348, 3.5379093286236456, 11.150776998971203, 9.636510860276006, 0.05599999999999999, -0.009333333333333332, -0.22866666666666666] \n",
      " distance =  14.1788079570828 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -16 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [-5.         -1.68027735  5.        ]\n",
      "\n",
      "\n",
      "STATE =  [-3.545827396215916, -10.360968367190134, -9.006444229226348, 3.5379093286236456, 11.150776998971203, 9.636510860276006, 0.05599999999999999, -0.009333333333333332, -0.22866666666666666]\n",
      "\n",
      " firstAngle =  14.879999999999995  secondAngle =  -5.280000000000001  thirdAngle =  -86.88 \n",
      "\n",
      "not normalize end pos: [2.5391697960781885, 12.363674580632107, 9.556324781048062]\n",
      "\n",
      " old state =  [-3.545827396215916, -10.360968367190134, -9.006444229226348, 3.5379093286236456, 11.150776998971203, 9.636510860276006, 0.05599999999999999, -0.009333333333333332, -0.22866666666666666] \n",
      " action =  [-5.         -1.68027735  5.        ] \n",
      " new state =  [-2.547087863670459, -11.573865948851038, -8.926258149998404, 2.5391697960781885, 12.363674580632107, 9.556324781048062, 0.04133333333333332, -0.01466666666666667, -0.24133333333333332] \n",
      " distance =  14.836445468765213 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -17 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [5. 5. 5.]\n",
      "\n",
      "\n",
      "STATE =  [-2.547087863670459, -11.573865948851038, -8.926258149998404, 2.5391697960781885, 12.363674580632107, 9.556324781048062, 0.04133333333333332, -0.01466666666666667, -0.24133333333333332]\n",
      "\n",
      " firstAngle =  19.680000000000007  secondAngle =  -0.23999999999999488  thirdAngle =  -92.64 \n",
      "\n",
      "not normalize end pos: [3.68282608402232, 12.552582224351115, 10.297058536617833]\n",
      "\n",
      " old state =  [-2.547087863670459, -11.573865948851038, -8.926258149998404, 2.5391697960781885, 12.363674580632107, 9.556324781048062, 0.04133333333333332, -0.01466666666666667, -0.24133333333333332] \n",
      " action =  [5. 5. 5.] \n",
      " new state =  [-3.6907441516145907, -11.762773592570046, -9.666991905568175, 3.68282608402232, 12.552582224351115, 10.297058536617833, 0.05466666666666668, -0.0006666666666666524, -0.25733333333333336] \n",
      " distance =  15.666370590697168 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -18 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [-5.  5.  5.]\n",
      "\n",
      "\n",
      "STATE =  [-3.6907441516145907, -11.762773592570046, -9.666991905568175, 3.68282608402232, 12.552582224351115, 10.297058536617833, 0.05466666666666668, -0.0006666666666666524, -0.25733333333333336]\n",
      "\n",
      " firstAngle =  14.400000000000006  secondAngle =  4.799999999999997  thirdAngle =  -97.44 \n",
      "\n",
      "not normalize end pos: [2.9824033618593266, 12.464578601443426, 11.615694184120398]\n",
      "\n",
      " old state =  [-3.6907441516145907, -11.762773592570046, -9.666991905568175, 3.68282608402232, 12.552582224351115, 10.297058536617833, 0.05466666666666668, -0.0006666666666666524, -0.25733333333333336] \n",
      " action =  [-5.  5.  5.] \n",
      " new state =  [-2.990321429451597, -11.674769969662357, -10.98562755307074, 2.9824033618593266, 12.464578601443426, 11.615694184120398, 0.040000000000000015, 0.013333333333333326, -0.27066666666666667] \n",
      " distance =  16.30724651284681 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -19 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [4.99975777 1.03476882 5.        ]\n",
      "\n",
      "\n",
      "STATE =  [-2.990321429451597, -11.674769969662357, -10.98562755307074, 2.9824033618593266, 12.464578601443426, 11.615694184120398, 0.040000000000000015, 0.013333333333333326, -0.27066666666666667]\n",
      "\n",
      " firstAngle =  19.19999999999999  secondAngle =  5.040000000000006  thirdAngle =  -102.0 \n",
      "\n",
      "not normalize end pos: [3.9375714196933025, 13.286543553844224, 11.307164900296778]\n",
      "\n",
      " old state =  [-2.990321429451597, -11.674769969662357, -10.98562755307074, 2.9824033618593266, 12.464578601443426, 11.615694184120398, 0.040000000000000015, 0.013333333333333326, -0.27066666666666667] \n",
      " action =  [4.99975777 1.03476882 5.        ] \n",
      " new state =  [-3.945489487285573, -12.496734922063155, -10.67709826924712, 3.9375714196933025, 13.286543553844224, 11.307164900296778, 0.0533333333333333, 0.014000000000000018, -0.2833333333333333] \n",
      " distance =  16.903718480197 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -20 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [-5.  5.  5.]\n",
      "\n",
      "\n",
      "STATE =  [-3.945489487285573, -12.496734922063155, -10.67709826924712, 3.9375714196933025, 13.286543553844224, 11.307164900296778, 0.0533333333333333, 0.014000000000000018, -0.2833333333333333]\n",
      "\n",
      " firstAngle =  13.680000000000007  secondAngle =  9.360000000000014  thirdAngle =  -107.76 \n",
      "\n",
      "not normalize end pos: [3.0351433771882, 13.447144644680941, 12.469573471070698]\n",
      "\n",
      " old state =  [-3.945489487285573, -12.496734922063155, -10.67709826924712, 3.9375714196933025, 13.286543553844224, 11.307164900296778, 0.0533333333333333, 0.014000000000000018, -0.2833333333333333] \n",
      " action =  [-5.  5.  5.] \n",
      " new state =  [-3.0430614447804705, -12.657336012899872, -11.83950684002104, 3.0351433771882, 13.447144644680941, 12.469573471070698, 0.03800000000000002, 0.026000000000000037, -0.29933333333333334] \n",
      " distance =  17.596655935576692 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -21 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [4.99999714 4.73406649 5.        ]\n",
      "\n",
      "\n",
      "STATE =  [-3.0430614447804705, -12.657336012899872, -11.83950684002104, 3.0351433771882, 13.447144644680941, 12.469573471070698, 0.03800000000000002, 0.026000000000000037, -0.29933333333333334]\n",
      "\n",
      " firstAngle =  18.24000000000001  secondAngle =  13.919999999999987  thirdAngle =  -113.52 \n",
      "\n",
      "not normalize end pos: [4.298326719092726, 13.482047018291455, 13.042739496873727]\n",
      "\n",
      " old state =  [-3.0430614447804705, -12.657336012899872, -11.83950684002104, 3.0351433771882, 13.447144644680941, 12.469573471070698, 0.03800000000000002, 0.026000000000000037, -0.29933333333333334] \n",
      " action =  [4.99999714 4.73406649 5.        ] \n",
      " new state =  [-4.306244786684997, -12.692238386510386, -12.412672865824069, 4.298326719092726, 13.482047018291455, 13.042739496873727, 0.05066666666666669, 0.038666666666666634, -0.3153333333333333] \n",
      " distance =  18.267761414492597 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -22 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [-5. -5.  5.]\n",
      "\n",
      "\n",
      "STATE =  [-4.306244786684997, -12.692238386510386, -12.412672865824069, 4.298326719092726, 13.482047018291455, 13.042739496873727, 0.05066666666666669, 0.038666666666666634, -0.3153333333333333]\n",
      "\n",
      " firstAngle =  13.439999999999998  secondAngle =  9.120000000000005  thirdAngle =  -118.8 \n",
      "\n",
      "not normalize end pos: [2.849439046468052, 15.552735097621472, 11.923761909168148]\n",
      "\n",
      " old state =  [-4.306244786684997, -12.692238386510386, -12.412672865824069, 4.298326719092726, 13.482047018291455, 13.042739496873727, 0.05066666666666669, 0.038666666666666634, -0.3153333333333333] \n",
      " action =  [-5. -5.  5.] \n",
      " new state =  [-2.8573571140603224, -14.762926465840403, -11.29369527811849, 2.849439046468052, 15.552735097621472, 11.923761909168148, 0.03733333333333333, 0.025333333333333347, -0.33] \n",
      " distance =  18.805744881500388 \n",
      " current reward =  -1 \n",
      " cumulative reward =  -23 \n",
      "\n",
      "\n",
      "\n",
      "ACTION =  [5. 5. 5.]\n",
      "\n",
      "\n",
      "STATE =  [-2.8573571140603224, -14.762926465840403, -11.29369527811849, 2.849439046468052, 15.552735097621472, 11.923761909168148, 0.03733333333333333, 0.025333333333333347, -0.33]\n"
     ]
    }
   ],
   "source": [
    "n_episodes = 1\n",
    "\n",
    "test_rewards = []\n",
    "agent.saver.restore(agent.sess, \"model/without_her_rotate_scaled.ckpt\")\n",
    "for i_episode in range(n_episodes):\n",
    "    state, goal = read_state()\n",
    "    r = 0\n",
    "    while True:\n",
    "        action = agent.choose_action([state], [goal], 0)\n",
    "        print(\"\\n\\nACTION = \", action)\n",
    "        print(\"\\n\\nSTATE = \", state)\n",
    "        # применяем углы к сервам\n",
    "        #servo1, servo2, servo3 = set_action_test(action, servo1, servo2, servo3)\n",
    "        \n",
    "        set_action(action)\n",
    "        \n",
    "        # как-то ждем, пока сервы повернутся\n",
    "        #time.sleep(5)\n",
    "        \n",
    "        # получаем обновленный state\n",
    "        next_state, next_goal = read_state()\n",
    "        \n",
    "        done, distance = check_if_done(next_state[3:6], goal)\n",
    "        \n",
    "        reward = -1\n",
    "        \n",
    "        if done:\n",
    "            reward += 10\n",
    "        \n",
    "        r += reward\n",
    "        \n",
    "        print(\"\\n old state = \", state, \"\\n action = \", action, \"\\n new state = \", next_state, \"\\n distance = \", distance,\n",
    "              \"\\n current reward = \", reward, \"\\n cumulative reward = \", r, \"\\n\")\n",
    "        \n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"episode:\", i_episode+1, \"rewards: %.2f\" % r, end=\"\\r\")\n",
    "            test_rewards += [r]\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
